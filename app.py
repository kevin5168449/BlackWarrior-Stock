import streamlit as st
import yfinance as yf
import pandas as pd
import numpy as np
import time
import twstock
import os
import requests
import feedparser
from collections import Counter
from datetime import datetime, timedelta
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots

# â˜…â˜…â˜… ä¿®æ­£ï¼šå·²ç§»é™¤ FinMind å¼•ç”¨ï¼Œç¾åœ¨æ˜¯ç´”çˆ¬èŸ²æ¨¡å¼ â˜…â˜…â˜…

# ==========================================
# 0. ç³»çµ±è¨­å®š
# ==========================================
try:
    st.set_page_config(page_title="é»‘æ­¦å£«ãƒ»å…¨èƒ½æˆ°æƒ…å®¤", layout="wide", page_icon="âš”ï¸")
except: pass

HISTORY_FILE = "screening_history.csv"

# ç™½åå–®
VALID_STRATEGIES = [
    "ç±Œç¢¼è¡é‹’ (é›†ä¸­åº¦é«˜)", 
    "èœ»èœ“é»æ°´ (ç¸®é‡å›æ¸¬)", 
    "æµ´ç«é‡ç”Ÿ (å‡è·Œç ´)"
]

# ==========================================
# 1. æª”æ¡ˆèˆ‡æ¸…æ´— / å·¥å…·å‡½å¼
# ==========================================

def get_taiwan_time():
    return datetime.utcnow() + timedelta(hours=8)

def send_line_notify(token, message):
    url = "https://notify-api.line.me/api/notify"
    headers = {"Authorization": f"Bearer {token}"}
    data = {"message": message}
    try:
        requests.post(url, headers=headers, data=data, timeout=5)
    except: pass

def clean_invalid_data():
    if os.path.exists(HISTORY_FILE):
        try:
            df = pd.read_csv(HISTORY_FILE)
            if 'ç­–ç•¥' in df.columns:
                df_clean = df[df['ç­–ç•¥'].isin(VALID_STRATEGIES)]
                if len(df_clean) < len(df):
                    df_clean.to_csv(HISTORY_FILE, index=False, encoding='utf-8-sig')
        except: pass

def save_to_history(new_results):
    if not new_results: return
    df_new = pd.DataFrame(new_results)
    current_date = get_taiwan_time().strftime("%Y-%m-%d")
    df_new.insert(0, "ç¯©é¸æ—¥æœŸ", current_date)
    if "é€²å ´åƒ¹" not in df_new.columns and "æ”¶ç›¤" in df_new.columns:
        df_new["é€²å ´åƒ¹"] = df_new["æ”¶ç›¤"]
    
    if os.path.exists(HISTORY_FILE):
        df_old = pd.read_csv(HISTORY_FILE)
        for col in df_new.columns:
             if col not in df_old.columns: df_old[col] = "N/A"
        for col in df_old.columns:
             if col not in df_new.columns: df_new[col] = "N/A"
        df_combined = pd.concat([df_old, df_new], ignore_index=True)
        df_combined = df_combined[df_combined['ç­–ç•¥'].isin(VALID_STRATEGIES)]
        df_combined.drop_duplicates(subset=['ç¯©é¸æ—¥æœŸ', 'ä»£è™Ÿ', 'ç­–ç•¥'], keep='last', inplace=True)
    else:
        df_combined = df_new
    
    df_combined.to_csv(HISTORY_FILE, index=False, encoding='utf-8-sig')
    st.toast(f"âœ… ç´€éŒ„å·²å„²å­˜ (å«ç‡Ÿæ”¶èˆ‡ç±Œç¢¼)")

def load_history():
    if os.path.exists(HISTORY_FILE): 
        df = pd.read_csv(HISTORY_FILE)
        if 'ç”¢æ¥­' not in df.columns: df['ç”¢æ¥­'] = 'å…¶ä»–'
        if 'ç‡Ÿæ”¶å¹´å¢(%)' not in df.columns: df['ç‡Ÿæ”¶å¹´å¢(%)'] = "N/A"
        return df[df['ç­–ç•¥'].isin(VALID_STRATEGIES)]
    return None

def clear_history():
    if os.path.exists(HISTORY_FILE): os.remove(HISTORY_FILE)

clean_invalid_data()

# ==========================================
# 2. æ•¸æ“šç²å– (æ ¸å¿ƒå‡½æ•¸ - å„ªå…ˆåŠ è¼‰)
# ==========================================

@st.cache_data(ttl=86400)
def get_tw_stock_list():
    try:
        codes = twstock.codes
        tw_list = []
        for code in codes:
            if codes[code].type == "è‚¡ç¥¨":
                suffix = ".TW" if codes[code].market == "ä¸Šå¸‚" else ".TWO"
                tw_list.append(f"{code}{suffix}")
        return tw_list
    except: return []

@st.cache_data(ttl=86400)
def get_stock_name(code):
    try: return twstock.codes[code].name
    except: return code

SUB_SECTOR_MAP = {
    '2408': 'è¨˜æ†¶é«”', '2344': 'è¨˜æ†¶é«”', '2337': 'è¨˜æ†¶é«”', '3260': 'è¨˜æ†¶é«”', '8299': 'è¨˜æ†¶é«”',
    '3006': 'è¨˜æ†¶é«”', '2451': 'è¨˜æ†¶é«”', '4967': 'è¨˜æ†¶é«”', '5289': 'è¨˜æ†¶é«”',
    '2382': 'AIä¼ºæœå™¨', '3231': 'AIä¼ºæœå™¨', '2356': 'AIä¼ºæœå™¨', '6669': 'AIä¼ºæœå™¨', 
    '2317': 'AIä¼ºæœå™¨', '2301': 'AIä¼ºæœå™¨', '2376': 'AIä¼ºæœå™¨',
    '3017': 'æ•£ç†±', '3324': 'æ•£ç†±', '3338': 'æ•£ç†±', '3653': 'æ•£ç†±', '2421': 'æ•£ç†±',
    '2454': 'ICè¨­è¨ˆ', '3034': 'ICè¨­è¨ˆ', '2379': 'ICè¨­è¨ˆ', '3035': 'ICè¨­è¨ˆ', 
    '3529': 'ICè¨­è¨ˆ', '3443': 'ICè¨­è¨ˆ', '8016': 'ICè¨­è¨ˆ', '6415': 'ICè¨­è¨ˆ',
    '1513': 'é‡é›»ç¶ èƒ½', '1519': 'é‡é›»ç¶ èƒ½', '1503': 'é‡é›»ç¶ èƒ½', '1504': 'é‡é›»ç¶ èƒ½',
    '1609': 'é‡é›»ç¶ èƒ½', '6806': 'é‡é›»ç¶ èƒ½',
    '2603': 'è²¨æ«ƒèˆªé‹', '2609': 'è²¨æ«ƒèˆªé‹', '2615': 'è²¨æ«ƒèˆªé‹', 
    '2618': 'èˆªç©º', '2610': 'èˆªç©º', '2637': 'æ•£è£èˆªé‹', '2606': 'æ•£è£èˆªé‹',
    '2330': 'æ™¶åœ“ä»£å·¥', '2303': 'æ™¶åœ“ä»£å·¥', '5347': 'æ™¶åœ“ä»£å·¥'
}

def get_stock_sector(code):
    if code in SUB_SECTOR_MAP: return SUB_SECTOR_MAP[code]
    try: return twstock.codes[code].group
    except: return "å…¶ä»–"

def get_last_trading_day(date_obj):
    offset = 1
    while True:
        prev = date_obj - timedelta(days=offset)
        if prev.weekday() < 5: return prev
        offset += 1

def get_market_temperature():
    try:
        tickers = ['^TWII', '^VIX']
        data = yf.download(tickers, period='5d', progress=False)['Close']
        if not data.empty:
            twii_curr = data['^TWII'].iloc[-1]
            twii_prev = data['^TWII'].iloc[-2]
            twii_pct = ((twii_curr - twii_prev) / twii_prev) * 100
            vix_curr = data['^VIX'].iloc[-1]
            vix_change = vix_curr - data['^VIX'].iloc[-2]
            return {
                'twii': f"{int(twii_curr):,}",
                'twii_change': f"{(twii_curr - twii_prev):+.2f} ({twii_pct:+.2f}%)",
                'vix': f"{vix_curr:.2f}",
                'vix_change': f"{vix_change:+.2f}"
            }
    except: return None
    return None

def calculate_rsi(data, window=14):
    delta = data['Close'].diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()
    rs = gain / loss
    return 100 - (100 / (1 + rs))

def fetch_raw_data(ticker, period="1y"):
    ticker = ticker.strip().upper()
    if not (ticker.endswith(".TW") or ticker.endswith(".TWO")): ticker = f"{ticker}.TW"
    try:
        data = yf.Ticker(ticker).history(period=period)
        if len(data) > 20: 
            data.index = data.index.tz_localize(None)
            return data
    except: pass
    return None

def add_technical_indicators(data_df):
    try:
        data_df['MA5'] = data_df['Close'].rolling(window=5).mean()
        data_df['MA20'] = data_df['Close'].rolling(window=20).mean()
        data_df['MA60'] = data_df['Close'].rolling(window=60).mean()
        data_df['MA200'] = data_df['Close'].rolling(window=200).mean()
        data_df['Volume_MA5'] = data_df['Volume'].rolling(window=5).mean()
        data_df['Volume_MA60'] = data_df['Volume'].rolling(window=60).mean()
        data_df['RSI'] = calculate_rsi(data_df)
        return data_df
    except: return None

def get_stock_fundamentals_safe(ticker):
    try:
        if not ticker.endswith('.TW') and not ticker.endswith('.TWO'): ticker += '.TW'
        stock = yf.Ticker(ticker)
        info = stock.info
        eps = info.get('trailingEps', None)
        pe = info.get('trailingPE', None)
        roe = info.get('returnOnEquity', None)
        return eps, pe, roe
    except: return None, None, None

# â˜…â˜…â˜… é—œéµä¿®æ­£ï¼šåŠ å…¥å½è£ Headers â˜…â˜…â˜…
HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
}

# --- ç‡Ÿæ”¶ (MOPS) ---
@st.cache_data(ttl=3600)
def get_revenue_data_snapshot():
    date_obj = get_taiwan_time()
    if date_obj.day < 12: 
        target_month = date_obj.replace(day=1) - timedelta(days=1)
        target_month = target_month.replace(day=1) - timedelta(days=1)
    else:
        target_month = date_obj.replace(day=1) - timedelta(days=1)
        
    for _ in range(2): 
        roc_year = target_month.year - 1911
        month = target_month.month
        revenue_map = {}
        urls = [
            f"https://mops.twse.com.tw/nas/t21/sii/t21sc03_{roc_year}_{month}_0.html",
            f"https://mops.twse.com.tw/nas/t21/otc/t21sc03_{roc_year}_{month}_0.html" 
        ]
        has_data = False
        for url in urls:
            try:
                # â˜… åŠ å…¥ Headers + verify=False
                res = requests.get(url, headers=HEADERS, timeout=3, verify=False)
                res.encoding = 'utf-8'
                dfs = pd.read_html(res.text)
                for df in dfs:
                    if df.shape[1] > 5 and 'å…¬å¸ä»£è™Ÿ' in str(df.columns):
                        df.columns = [str(c).replace(' ','') for c in df.columns] 
                        col_code = None
                        col_yoy = None
                        col_mom = None
                        for i, col in enumerate(df.columns):
                            if 'ä»£è™Ÿ' in col: col_code = col
                            if 'å»å¹´' in col and '%' in col: col_yoy = col
                            if 'ä¸Šæœˆ' in col and '%' in col: col_mom = col
                        if col_code and col_yoy:
                            for _, row in df.iterrows():
                                try:
                                    code = str(row[col_code])
                                    if code == 'nan' or code == 'åˆè¨ˆ': continue
                                    yoy = float(str(row[col_yoy]).replace(',',''))
                                    mom = float(str(row[col_mom]).replace(',','')) if col_mom else 0.0
                                    revenue_map[code] = {'yoy': yoy, 'mom': mom}
                                    has_data = True
                                except: continue
            except: pass
        if has_data: return revenue_map, f"{roc_year}/{month}"
        target_month = target_month.replace(day=1) - timedelta(days=1)
    return {}, "ç„¡è³‡æ–™ (é€£ç·šé€¾æ™‚)"

# --- èè³‡ (TWSE + TPEx) ---
@st.cache_data(ttl=3600)
def get_tpex_margin_data_snapshot(date_obj):
    roc_year = int(date_obj.strftime('%Y')) - 1911
    date_str = f"{roc_year}/{date_obj.strftime('%m/%d')}"
    url = f"https://www.tpex.org.tw/web/stock/margin_trading/margin_balance/margin_bal_result.php?l=zh-tw&o=json&d={date_str}&s=0,asc,0"
    try:
        res = requests.get(url, headers=HEADERS, timeout=5)
        data = res.json()
        if 'aaData' in data:
            margin_dict = {}
            for row in data['aaData']:
                try:
                    code = row[0]
                    today_bal = int(row[6].replace(',', ''))
                    yest_bal = int(row[2].replace(',', ''))
                    net_change = (today_bal - yest_bal) / 1000 
                    margin_dict[code] = net_change
                except: continue
            return margin_dict
    except: pass
    return {}

@st.cache_data(ttl=3600)
def get_margin_data_snapshot():
    date_obj = get_taiwan_time()
    if date_obj.hour < 21: date_obj -= timedelta(days=1)
    for _ in range(3):
        if date_obj.weekday() >= 5: 
            date_obj -= timedelta(days=1); continue
        date_str = date_obj.strftime('%Y%m%d')
        
        twse_dict = {}
        try:
            url = f"https://www.twse.com.tw/rwd/zh/margin/MI_MARGN?date={date_str}&selectType=STOCK&response=json"
            res = requests.get(url, headers=HEADERS, timeout=5)
            data = res.json()
            if data['stat'] == 'OK':
                for table in data.get('tables', []):
                    if 'è‚¡ç¥¨ä»£è™Ÿ' in table['fields'] and 'èè³‡ä»Šæ—¥é¤˜é¡' in table['fields']:
                        df = pd.DataFrame(table['data'], columns=table['fields'])
                        for col in ['èè³‡å‰æ—¥é¤˜é¡', 'èè³‡ä»Šæ—¥é¤˜é¡']:
                             df[col] = pd.to_numeric(df[col].astype(str).str.replace(',', ''), errors='coerce').fillna(0)
                        df['net_change'] = (df['èè³‡ä»Šæ—¥é¤˜é¡'] - df['èè³‡å‰æ—¥é¤˜é¡']) / 1000
                        twse_dict = df.set_index('è‚¡ç¥¨ä»£è™Ÿ')['net_change'].to_dict()
                        break
        except: pass

        tpex_dict = get_tpex_margin_data_snapshot(date_obj)
        if twse_dict or tpex_dict:
            twse_dict.update(tpex_dict)
            return twse_dict
            
        date_obj -= timedelta(days=1)
    return {}

# --- ç±Œç¢¼ (TWSE + TPEx) ---
@st.cache_data(ttl=3600)
def get_tpex_chip_data_snapshot(date_obj):
    roc_year = int(date_obj.strftime('%Y')) - 1911
    date_str = f"{roc_year}/{date_obj.strftime('%m/%d')}"
    url = f"https://www.tpex.org.tw/web/stock/3insti/daily_trade/3itrade_hedge_result.php?l=zh-tw&o=json&se=EW&t=D&d={date_str}"
    try:
        res = requests.get(url, headers=HEADERS, timeout=5)
        data = res.json()
        if 'aaData' in data:
            chip_dict = {}
            for row in data['aaData']:
                code = row[0]
                try:
                    net_buy = int(row[-1].replace(',', '')) 
                    chip_dict[code] = net_buy
                except: continue
            return chip_dict
    except: pass
    return {}

@st.cache_data(ttl=3600)
def get_chip_data_snapshot():
    date_obj = get_taiwan_time()
    if date_obj.hour < 15: date_obj -= timedelta(days=1)
    for _ in range(3):
        if date_obj.weekday() >= 5:
            date_obj -= timedelta(days=1); continue
        date_str_twse = date_obj.strftime('%Y%m%d')
        
        twse_dict = {}
        try:
            url = f"https://www.twse.com.tw/rwd/zh/fund/T86?date={date_str_twse}&selectType=ALL&response=json"
            res = requests.get(url, headers=HEADERS, timeout=5)
            data = res.json()
            if data['stat'] == 'OK':
                df = pd.DataFrame(data['data'], columns=data['fields'])
                df['ä¸‰å¤§æ³•äººè²·è³£è¶…è‚¡æ•¸'] = pd.to_numeric(df['ä¸‰å¤§æ³•äººè²·è³£è¶…è‚¡æ•¸'].astype(str).str.replace(',', ''), errors='coerce').fillna(0)
                twse_dict = df.set_index('è­‰åˆ¸ä»£è™Ÿ')['ä¸‰å¤§æ³•äººè²·è³£è¶…è‚¡æ•¸'].to_dict()
        except: pass

        tpex_dict = get_tpex_chip_data_snapshot(date_obj)
        if twse_dict or tpex_dict:
            twse_dict.update(tpex_dict)
            return twse_dict, date_str_twse
            
        date_obj -= timedelta(days=1)
    return {}, "ç„¡è³‡æ–™"

def calculate_chip_concentration_pct(stock_id, chip_map, current_volume):
    net_buy_shares = chip_map.get(stock_id, 0)
    if not chip_map: return 0.0 
    if net_buy_shares <= 0 or current_volume <= 0: return 0.0
    return (net_buy_shares / current_volume) * 100.0

@st.cache_data(ttl=600)
def get_tw_market_heatmap_data():
    date_obj = get_taiwan_time()
    if date_obj.hour < 14: date_obj -= timedelta(days=1)
    for _ in range(5):
        if date_obj.weekday() >= 5: 
            date_obj -= timedelta(days=1); continue
        date_str = date_obj.strftime('%Y%m%d')
        url = f"https://www.twse.com.tw/rwd/zh/afterTrading/MI_INDEX?date={date_str}&type=ALLBUT0999&response=json"
        try:
            res = requests.get(url, headers=HEADERS, timeout=15)
            data = res.json()
            if data['stat'] == 'OK':
                target_table = None
                for table in data.get('tables', []):
                    if 'è­‰åˆ¸ä»£è™Ÿ' in table['fields'] and 'æ”¶ç›¤åƒ¹' in table['fields']:
                        target_table = table; break
                if target_table:
                    df = pd.DataFrame(target_table['data'], columns=target_table['fields'])
                    df['æˆäº¤é‡‘é¡'] = pd.to_numeric(df['æˆäº¤é‡‘é¡'].astype(str).str.replace(',', '').replace('--', '0'), errors='coerce').fillna(0)
                    df['æ”¶ç›¤åƒ¹'] = pd.to_numeric(df['æ”¶ç›¤åƒ¹'].astype(str).str.replace(',', '').replace('--', '0'), errors='coerce').fillna(0)
                    df['æ¼²è·Œåƒ¹å·®'] = pd.to_numeric(df['æ¼²è·Œåƒ¹å·®'].astype(str).str.replace(',', '').replace('--', '0'), errors='coerce').fillna(0)
                    def parse_sign(txt): return 1 if '+' in txt else (-1 if '-' in txt else 0)
                    df['sign'] = df['æ¼²è·Œ(+/-)'].astype(str).apply(parse_sign)
                    df['æ¼²è·Œé‡‘é¡'] = df['æ¼²è·Œåƒ¹å·®'] * df['sign']
                    df['æ˜¨æ—¥æ”¶ç›¤'] = df['æ”¶ç›¤åƒ¹'] - df['æ¼²è·Œé‡‘é¡']
                    df['æ¼²è·Œå¹…%'] = 0.0
                    mask = df['æ˜¨æ—¥æ”¶ç›¤'] > 0
                    df.loc[mask, 'æ¼²è·Œå¹…%'] = (df.loc[mask, 'æ¼²è·Œé‡‘é¡'] / df.loc[mask, 'æ˜¨æ—¥æ”¶ç›¤']) * 100
                    df['æ¼²è·Œå¹…%'] = df['æ¼²è·Œå¹…%'].round(2)
                    df_top = df.sort_values('æˆäº¤é‡‘é¡', ascending=False).head(400).copy() 
                    def get_sector_enhanced(code):
                        if code in SUB_SECTOR_MAP: return SUB_SECTOR_MAP[code]
                        try: return twstock.codes[code].group
                        except: return "å…¶ä»–"
                    df_top['ç”¢æ¥­'] = df_top['è­‰åˆ¸ä»£è™Ÿ'].apply(get_sector_enhanced)
                    df_top['æ¨™ç±¤'] = df_top['è­‰åˆ¸åç¨±'] + "<br>" + df_top['æ¼²è·Œå¹…%'].astype(str) + "%"
                    return df_top, date_str
        except: pass
        date_obj -= timedelta(days=1)
    return None, "ç„¡è³‡æ–™"

@st.cache_data(ttl=1800)
def get_all_market_news():
    rss_sources = {
        "Yahooå€‹è‚¡": "https://tw.stock.yahoo.com/rss?category=tw-individual",
        "Yahooç”¢æ¥­": "https://tw.stock.yahoo.com/rss?category=tw-industry",
        "MoneyDJå€‹è‚¡": "https://www.moneydj.com/KMDJ/RssCenter.aspx?svc=NW&a=X0100000",
        "MoneyDJç”¢æ¥­": "https://www.moneydj.com/KMDJ/RssCenter.aspx?svc=NW&a=X0200000"
    }
    all_news = []
    seen_titles = set()
    keywords = []
    for source, url in rss_sources.items():
        try:
            feed = feedparser.parse(url)
            for entry in feed.entries[:8]: 
                if entry.title not in seen_titles:
                    all_news.append({"ä¾†æº": source, "æ¨™é¡Œ": entry.title, "é€£çµ": entry.link, "æ™‚é–“": entry.get('published', '')})
                    seen_titles.add(entry.title)
                    if "ç‡Ÿæ”¶" in entry.title: keywords.append("ç‡Ÿæ”¶")
                    if "æ³•èªª" in entry.title: keywords.append("æ³•èªª")
                    if "æ–°é«˜" in entry.title: keywords.append("å‰µæ–°é«˜")
        except: pass
    return all_news, keywords

@st.cache_data(ttl=600)
def get_twse_sector_flow_dynamic():
    url_base = "https://www.twse.com.tw/rwd/zh/afterTrading/BFIAMU?response=json"
    try:
        res = requests.get(url_base, timeout=10)
        data = res.json()
        if data.get('stat') != 'OK': return None, "ç„¡è³‡æ–™", None, None
        df_curr = pd.DataFrame(data['data'], columns=data['fields'])
        df_curr['æˆäº¤é‡‘é¡'] = pd.to_numeric(df_curr['æˆäº¤é‡‘é¡'].astype(str).str.replace(',', ''), errors='coerce').fillna(0)
        total_curr = df_curr['æˆäº¤é‡‘é¡'].sum()
        df_curr['ä»Šæ—¥ä½”æ¯”%'] = (df_curr['æˆäº¤é‡‘é¡'] / total_curr) * 100 if total_curr > 0 else 0
        if df_curr['æ¼²è·ŒæŒ‡æ•¸'].astype(str).str.contains('<').any():
             df_curr['æ¼²è·ŒæŒ‡æ•¸'] = df_curr['æ¼²è·ŒæŒ‡æ•¸'].astype(str).str.extract(r'>([-\d\.]+)<')[0]
        today = datetime.strptime(data['date'], '%Y%m%d')
        prev_str = get_last_trading_day(today).strftime('%Y%m%d')
        try:
            res_p = requests.get(f"{url_base}&date={prev_str}", timeout=5)
            data_p = res_p.json()
            if data_p.get('stat') == 'OK':
                df_p = pd.DataFrame(data_p['data'], columns=data_p['fields'])
                df_p['æˆäº¤é‡‘é¡'] = pd.to_numeric(df_p['æˆäº¤é‡‘é¡'].astype(str).str.replace(',', ''), errors='coerce').fillna(0)
                total_p = df_p['æˆäº¤é‡‘é¡'].sum()
                df_p['æ˜¨æ—¥ä½”æ¯”%'] = (df_p['æˆäº¤é‡‘é¡'] / total_p) * 100 if total_p > 0 else 0
                df_merge = pd.merge(df_curr, df_p[['åˆ†é¡æŒ‡æ•¸åç¨±', 'æ˜¨æ—¥ä½”æ¯”%']], on='åˆ†é¡æŒ‡æ•¸åç¨±', how='left')
                df_merge['è³‡é‡‘è®Šå‹•%'] = df_merge['ä»Šæ—¥ä½”æ¯”%'] - df_merge['æ˜¨æ—¥ä½”æ¯”%'].fillna(0)
            else: df_merge = df_curr; df_merge['è³‡é‡‘è®Šå‹•%'] = 0
        except: df_merge = df_curr; df_merge['è³‡é‡‘è®Šå‹•%'] = 0
        df_merge = df_merge.round(1)
        flow_in = df_merge.sort_values('è³‡é‡‘è®Šå‹•%', ascending=False).head(5)
        flow_out = df_merge.sort_values('è³‡é‡‘è®Šå‹•%', ascending=True).head(5)
        main_s = df_merge.sort_values('æˆäº¤é‡‘é¡', ascending=False).head(10)
        return main_s, flow_in, flow_out, data['date']
    except Exception as e: return None, str(e), None, None

@st.cache_data(ttl=600)
def get_institutional_ranking_smart():
    url = "https://www.twse.com.tw/rwd/zh/fund/T86?response=json&selectType=ALL"
    try:
        res = requests.get(url, timeout=10)
        data = res.json()
        if data.get('stat') != 'OK': return None, "ç„¡è³‡æ–™"
        df = pd.DataFrame(data['data'], columns=data['fields'])
        target_col = 'ä¸‰å¤§æ³•äººè²·è³£è¶…è‚¡æ•¸'
        for c in df.columns:
            if 'ä¸‰å¤§æ³•äºº' in c and 'è²·è³£è¶…' in c: target_col = c; break
        df[target_col] = pd.to_numeric(df[target_col].astype(str).str.replace(',', ''), errors='coerce').fillna(0).astype(int)
        df_today = df[['è­‰åˆ¸ä»£è™Ÿ', 'è­‰åˆ¸åç¨±', target_col]].copy()
        df_today.columns = ['ä»£è™Ÿ', 'åç¨±', 'ä»Šæ—¥è²·è¶…']
        top_list = df_today.sort_values('ä»Šæ—¥è²·è¶…', ascending=False).head(30).copy()
        today = datetime.strptime(data['date'], '%Y%m%d')
        prev_str = get_last_trading_day(today).strftime('%Y%m%d')
        try:
            res_p = requests.get(f"https://www.twse.com.tw/rwd/zh/fund/T86?date={prev_str}&response=json&selectType=ALL", timeout=5)
            d_p = res_p.json()
            if d_p.get('stat') == 'OK':
                df_p = pd.DataFrame(d_p['data'], columns=d_p['fields'])
                df_p[target_col] = pd.to_numeric(df_p[target_col].astype(str).str.replace(',', ''), errors='coerce').fillna(0).astype(int)
                df_p = df_p[['è­‰åˆ¸ä»£è™Ÿ', target_col]]
                df_p.columns = ['ä»£è™Ÿ', 'æ˜¨æ—¥è²·è¶…']
                top_list = pd.merge(top_list, df_p, on='ä»£è™Ÿ', how='left').fillna(0)
            else: top_list['æ˜¨æ—¥è²·è¶…'] = 0
        except: top_list['æ˜¨æ—¥è²·è¶…'] = 0
        def label(row):
            t, y = row['ä»Šæ—¥è²·è¶…'], row['æ˜¨æ—¥è²·è¶…']
            if t > 0 and y > 0: return "ğŸš€ çˆ†è²·" if t > y*2 and t>1000000 else "ğŸ”¥ é€£è²·"
            if t > 0 and y < 0: return "âš¡ å¼·å‹¢è½‰è²·" if t > abs(y) else "âš¡ è½‰è²·"
            return "ğŸ’° å¤§æˆ¶é€²å ´" if t > 2000000 else "è²·è¶…"
        top_list['ç‹€æ…‹'] = top_list.apply(label, axis=1)
        top_list['ä»Šæ—¥(å¼µ)'] = (top_list['ä»Šæ—¥è²·è¶…']/1000).astype(int)
        return top_list[['ä»£è™Ÿ', 'åç¨±', 'ä»Šæ—¥(å¼µ)', 'ç‹€æ…‹']], data['date']
    except Exception as e: return None, str(e)

# ==========================================
# 3. æ ¸å¿ƒç­–ç•¥
# ==========================================

def is_bullish_candlestick(open_p, close_p, high_p, low_p):
    if close_p > open_p: return True
    total_len = high_p - low_p
    body_len = abs(close_p - open_p)
    if total_len > 0 and (body_len / total_len < 0.1): return True
    if open_p > 0 and (body_len / open_p < 0.003): return True
    lower_shadow = min(open_p, close_p) - low_p
    if total_len > 0 and (lower_shadow / total_len > 0.5): return True
    return False

def check_stock_strategy_web(df, settings, ticker="", chip_map=None):
    if df is None or len(df) < 60: return False
    curr = df.iloc[-1]
    prev = df.iloc[-2]
    strategy = settings['strategy']
    stock_id = ticker.split('.')[0] if ticker else ""
    
    if strategy != 'èœ»èœ“é»æ°´ (ç¸®é‡å›æ¸¬)':
        if pd.isna(curr['MA200']): return False
        bias = ((curr['Close'] - curr['MA200']) / curr['MA200']) * 100
        if strategy != 'æµ´ç«é‡ç”Ÿ (å‡è·Œç ´)' and abs(bias) > settings['bias_range']: return False

    if settings['check_trend_high']:
        past_60 = df.iloc[-65:-5]
        if not past_60.empty and not pd.isna(curr['MA200']):
            past_high = past_60['Close'].max()
            if past_high <= (curr['MA200'] * 1.05): return False

    if settings['check_rsi_rising']:
        if pd.isna(curr['RSI']) or curr['RSI'] <= prev['RSI']: return False 
    
    if settings['vol_surge']:
        if curr['Volume'] <= prev['Volume']: return False 
    
    if settings['check_red_candle']:
        if not is_bullish_candlestick(curr['Open'], curr['Close'], curr['High'], curr['Low']): return False

    # ç­–ç•¥é‚è¼¯
    if strategy == 'ç±Œç¢¼è¡é‹’ (é›†ä¸­åº¦é«˜)':
        if curr['Close'] <= curr['MA20']: return False
        chip_status = "âš ï¸ ç„¡ç±Œç¢¼æ•¸æ“š"
        if chip_map:
            concentration = calculate_chip_concentration_pct(stock_id, chip_map, curr['Volume'])
            if concentration >= settings.get('chip_threshold', 10.0):
                net_buy = int(chip_map.get(stock_id, 0) / 1000)
                chip_status = f"ç±Œç¢¼é›†ä¸­ {concentration:.1f}% (è²·è¶…{net_buy}å¼µ)"
            else: return False
        return True, chip_status
    
    elif strategy == 'èœ»èœ“é»æ°´ (ç¸®é‡å›æ¸¬)':
        if curr['Close'] < curr['MA200']: return False
        if curr['Low'] > curr['MA200'] * 1.03: return False 
        if pd.isna(curr['Volume_MA5']) or curr['Volume'] > curr['Volume_MA5']: return False 
        net_buy = 0
        if chip_map: net_buy = int(chip_map.get(stock_id, 0) / 1000)
        return True, f"é‡ç¸®æœ‰æ’ (è²·è¶…{net_buy}å¼µ)"

    elif strategy == 'æµ´ç«é‡ç”Ÿ (å‡è·Œç ´)':
        if curr['Close'] <= curr['MA200']: return False
        past_10 = df.iloc[-11:-1]
        if past_10.empty: return False
        is_break = (past_10['Low'] < past_10['MA200']).any()
        if is_break:
            net_buy = 0
            if chip_map: net_buy = int(chip_map.get(stock_id, 0) / 1000)
            return True, f"å‡è·Œç ´å›ç©© (è²·è¶…{net_buy}å¼µ)"

    return False

# ==========================================
# 4. å›æ¸¬æ ¸å¿ƒ
# ==========================================
def calculate_forward_performance(df, signal_loc):
    results = {}
    try:
        signal_price = df['Close'].iloc[signal_loc]
        future_data = df.iloc[signal_loc + 1 : ] 
        if not future_data.empty:
            max_price = future_data['High'].max()
            max_idx = future_data['High'].idxmax()
            if signal_price > 0:
                max_gain = ((max_price - signal_price) / signal_price) * 100
            else: max_gain = 0
            results["æ³¢æ®µæœ€é«˜æ¼²å¹…(%)"] = round(max_gain, 2)
            results["æœ€é«˜åƒ¹æ—¥æœŸ"] = max_idx.strftime('%Y-%m-%d')
            results["æŒæœ‰å¤©æ•¸"] = (max_idx - df.index[signal_loc]).days
        else:
            results["æ³¢æ®µæœ€é«˜æ¼²å¹…(%)"] = 0.0
            results["æœ€é«˜åƒ¹æ—¥æœŸ"] = "N/A"
            results["æŒæœ‰å¤©æ•¸"] = 0
    except:
        results["æ³¢æ®µæœ€é«˜æ¼²å¹…(%)"] = 0.0
        results["æœ€é«˜åƒ¹æ—¥æœŸ"] = "Error"
        results["æŒæœ‰å¤©æ•¸"] = 0
    return results

def check_signal_on_date(df, target_date_str, settings, strict_mode=True):
    target_date = pd.to_datetime(target_date_str)
    df_sorted = df.sort_index()
    try:
        target_loc = df_sorted.index.get_loc(target_date, method='nearest')
        if target_loc < 60: return False, None, None
        curr = df_sorted.iloc[target_loc]
        prev = df_sorted.iloc[target_loc - 1]
        strategy = settings['strategy']
        
        if (curr['Volume'] / 1000) < settings['vol_min']: return False, None, None
        bias = 0
        if strategy != 'èœ»èœ“é»æ°´ (ç¸®é‡å›æ¸¬)':
            if pd.isna(curr['MA200']): return False, None, None
            bias = ((curr['Close'] - curr['MA200']) / curr['MA200']) * 100
            if strategy != 'æµ´ç«é‡ç”Ÿ (å‡è·Œç ´)' and abs(bias) > settings['bias_range']: return False, None, None
        
        is_signal = False
        if strategy == 'ç±Œç¢¼è¡é‹’ (é›†ä¸­åº¦é«˜)':
             if (curr['Close'] > curr['MA20']) and (curr['Volume'] > prev['Volume'] * 1.5) and (curr['Close'] > curr['Open']): is_signal = True
        elif strategy == 'èœ»èœ“é»æ°´ (ç¸®é‡å›æ¸¬)':
            if (curr['Close'] > curr['MA200']) and (curr['Low'] <= curr['MA200'] * 1.03) and (curr['Volume'] < curr['Volume_MA5']): is_signal = True
        elif strategy == 'æµ´ç«é‡ç”Ÿ (å‡è·Œç ´)':
            if curr['Close'] > curr['MA200']:
                past_7 = df_sorted.iloc[target_loc - 8 : target_loc] 
                is_break = (past_7['Low'] < past_7['MA200']).any()
                if is_break: is_signal = True
        if is_signal: return True, round(bias, 2), target_loc
        else: return False, None, None
    except: return False, None, None

def plot_candlestick(df, signal_date_str, ticker):
    signal_date = pd.to_datetime(signal_date_str)
    fig = make_subplots(rows=2, cols=1, shared_xaxes=True, vertical_spacing=0.05, row_heights=[0.7, 0.3])
    fig.add_trace(go.Candlestick(
        x=df.index, open=df['Open'], high=df['High'], low=df['Low'], close=df['Close'],
        name='Kç·š', increasing_line_color='#ef5350', decreasing_line_color='#26a69a'
    ), row=1, col=1)
    fig.add_trace(go.Scatter(x=df.index, y=df['MA20'], line=dict(color='orange', width=1), name='MA20'), row=1, col=1)
    fig.add_trace(go.Scatter(x=df.index, y=df['MA60'], line=dict(color='green', width=1), name='MA60'), row=1, col=1)
    fig.add_trace(go.Scatter(x=df.index, y=df['MA200'], line=dict(color='blue', width=1.5), name='MA200'), row=1, col=1)
    colors = ['#ef5350' if c >= o else '#26a69a' for c, o in zip(df['Close'], df['Open'])]
    fig.add_trace(go.Bar(x=df.index, y=df['Volume'], name='æˆäº¤é‡', marker_color=colors), row=2, col=1)
    try:
        if signal_date in df.index:
            signal_price = df.loc[signal_date, 'High'] * 1.02
            fig.add_trace(go.Scatter(
                x=[signal_date], y=[signal_price],
                mode='markers+text', marker=dict(size=14, color='purple', symbol='triangle-down'),
                text=["é»‘æ­¦å£«!"], textposition="top center", name=f'è¨Šè™Ÿæ—¥'
            ), row=1, col=1)
    except: pass
    fig.update_layout(title=f"<b>{ticker}</b> é»‘æ­¦å£«æˆ°æƒ…åœ–", height=700, xaxis_rangeslider_visible=False)
    st.plotly_chart(fig, use_container_width=True)

# ==========================================
# 6. ä¸»ç¨‹å¼
# ==========================================

try:
    st.title("ğŸ”¥ é»‘æ­¦å£«ãƒ»å…¨èƒ½æˆ°æƒ…å®¤")
    
    m_temp = get_market_temperature()
    if m_temp:
        col_t1, col_t2 = st.columns(2)
        col_t1.metric("ğŸ“Š åŠ æ¬ŠæŒ‡æ•¸ (TWII)", m_temp['twii'], m_temp['twii_change'])
        col_t2.metric("ğŸ˜° ææ…ŒæŒ‡æ•¸ (VIX)", m_temp['vix'], m_temp['vix_change'], delta_color="inverse")
    st.markdown("---")

    st.sidebar.header("ğŸ”§ ç³»çµ±è¨ºæ–· / é€šçŸ¥")
    line_token = st.sidebar.text_input("ğŸ”” Line Notify Token (é¸å¡«)", type="password")

    if st.sidebar.button("ğŸ› ï¸ æ¸¬è©¦é€£ç·š"):
        with st.sidebar.status("æ¸¬è©¦ä¸­..."):
            try:
                test_df = yf.Ticker("2330.TW").history(period="5d")
                if not test_df.empty: st.write("âœ… yfinance OK")
                else: st.error("âŒ yfinance Error")
                
                rev_map, rev_date = get_revenue_data_snapshot()
                if rev_map: st.write(f"âœ… ç‡Ÿæ”¶æ•¸æ“š OK ({rev_date})")
                else: st.warning("âš ï¸ ç‡Ÿæ”¶ç„¡è³‡æ–™")
                
                chip_map, d = get_chip_data_snapshot()
                if chip_map: st.write(f"âœ… ç±Œç¢¼ OK ({d})")
                else: st.warning("âš ï¸ ç±Œç¢¼ç„¡è³‡æ–™")
                
                margin_map = get_margin_data_snapshot()
                if margin_map: st.write(f"âœ… èè³‡ OK")
                else: st.warning("âš ï¸ èè³‡ç„¡è³‡æ–™")
            except Exception as e: st.error(f"Error: {e}")

    st.sidebar.header("âš”ï¸ æ‹›å¼é¸æ“‡")
    strategy_mode = st.sidebar.selectbox("é¸æ“‡ç­–ç•¥ï¼š", VALID_STRATEGIES, index=0)
    
    note = ""
    if strategy_mode == "ç±Œç¢¼è¡é‹’ (é›†ä¸­åº¦é«˜)": note = "â˜…æ”»æ“Šå‹ï¼šæ³•äººè²·è¶…ä½”ä»Šæ—¥æˆäº¤é‡ > 10%"
    elif strategy_mode == "èœ»èœ“é»æ°´ (ç¸®é‡å›æ¸¬)": note = "â˜…é˜²å®ˆå‹ï¼šé‡ç¸®ä¸ç ´ï¼å›æ¸¬å¹´ç·š3%å…§"
    elif strategy_mode == "æµ´ç«é‡ç”Ÿ (å‡è·Œç ´)": note = "â˜…åè½‰å‹ï¼šè·Œç ´å¹´ç·šå¾Œï¼Œå¼·å‹¢ç«™å›"
    st.sidebar.info(f"ğŸ’¡ **é‚è¼¯**ï¼š{note}")

    st.sidebar.markdown("---")
    st.sidebar.header("ğŸ¯ é€²éšæ¿¾ç¶²")
    check_trend_high = st.sidebar.checkbox("âœ… å‰æ³¢æ›¾å‰µé«˜ (60æ—¥é«˜ > å¹´ç·š5%)", value=False)
    check_rsi_rising = st.sidebar.checkbox("âœ… å‹•èƒ½è½‰å¼· (RSI > æ˜¨æ—¥)", value=False)
    vol_surge_check = st.sidebar.checkbox("âœ… é‡èƒ½å¢åŠ  (Vol > æ˜¨æ—¥)", value=False)
    check_red_candle = st.sidebar.checkbox("âœ… å¿…é ˆæ”¶ç´…/æœ‰æ’ (åå­—/ä¸‹å½±)", value=False)
    
    st.sidebar.markdown("---")
    st.sidebar.header("ğŸ›¡ï¸ é¿é›·é‡")
    exclude_negative_pe = st.sidebar.checkbox("âœ… å‰”é™¤è™§æè‚¡ (EPS<0 æˆ– PEç‚ºè² )", value=True)
    exclude_margin_surge = st.sidebar.checkbox("âœ… å‰”é™¤èè³‡æš´å¢ (æ•£æˆ¶>500å¼µ)", value=False)
    min_revenue_yoy = st.sidebar.number_input("ğŸ“‰ ç‡Ÿæ”¶å¹´å¢ç‡ (YoY) > %", value=-100, step=10, help="é è¨­ -100 è¡¨ç¤ºä¸éæ¿¾")
    
    st.sidebar.markdown("---")
    st.sidebar.header("âš™ï¸ åŸºç¤è¨­å®š")
    min_vol = st.sidebar.number_input("æœ€ä½æˆäº¤é‡ (å¼µ)", value=1000, step=100)
    max_bias = st.sidebar.slider("ä¹–é›¢ç‡ç¯„åœ (Â±%)", 0.1, 10.0, 5.0)
    
    chip_threshold = 10.0
    if strategy_mode == "ç±Œç¢¼è¡é‹’ (é›†ä¸­åº¦é«˜)":
        st.sidebar.markdown("---")
        chip_threshold = st.sidebar.slider("æ³•äººä½”æˆäº¤é‡ (%)", 5.0, 50.0, 10.0, 5.0)

    settings = {
        'strategy': strategy_mode, 'vol_surge': vol_surge_check, 
        'check_rsi_rising': check_rsi_rising, 'check_trend_high': check_trend_high,
        'check_red_candle': check_red_candle, 'chip_threshold': chip_threshold,
        'vol_min': min_vol, 'bias_range': max_bias, 'chip_flow_surge': False 
    }
    
    debug_stock = st.sidebar.text_input("ğŸ•µï¸â€â™‚ï¸ è¨ºæ–·ç‰¹å®šè‚¡ç¥¨ (ä¾‹: 2330)", "")

    if st.sidebar.button("ğŸ—‘ï¸ æ¸…ç©ºæ‰€æœ‰æ­·å²"):
        clear_history()
        st.sidebar.success("å·²æ¸…ç©º")
        st.rerun() 

    tab1, tab2, tab3, tab4, tab5, tab6, tab7, tab8 = st.tabs(["ğŸš€ ä»Šæ—¥æƒæ", "ğŸ“œ æ­·å²ç´€éŒ„", "ğŸ“Š åŸºæœ¬é¢å¥è¨º", "â³ å–®è‚¡å›æ¸¬", "ğŸ“° å€‹è‚¡æƒ…å ±", "ğŸš€ æ½›åŠ›é›·é”", "ğŸŒ¡ï¸ è³‡é‡‘ç†±åŠ›åœ–", "ğŸ§ª ç­–ç•¥å¯¦é©—å®¤"])

    with tab1:
        st.subheader(f"åŸ·è¡Œæ‹›å¼ï¼š{strategy_mode}")
        if st.button("ğŸ”¥ å•Ÿå‹•æƒæ (ä»Šæ—¥)", type="primary"):
            stock_list = get_tw_stock_list()
            results = []
            chip_map = {}
            margin_map = {}
            rev_map = {}
            
            with st.spinner("é›†æ°£ä¸­ (ä¸‹è¼‰å…¨å¸‚å ´ç±Œç¢¼ã€èè³‡ã€ç‡Ÿæ”¶)..."):
                chip_map, _ = get_chip_data_snapshot()
                rev_map, _ = get_revenue_data_snapshot()
                if exclude_margin_surge: margin_map = get_margin_data_snapshot()

            bar = st.progress(0.0)
            status_text = st.empty() 
            live_result_placeholder = st.empty() # â˜… ä¿®æ­£ï¼šä½¿ç”¨ placeholder æ›´æ–°ï¼Œé¿å…é‡è¤‡é¡¯ç¤º
            
            scanned_count = 0
            download_ok = 0
            vol_ok = 0
            total_stocks = len(stock_list)
            
            for i, ticker in enumerate(stock_list):
                prog = min(1.0, (i + 1) / total_stocks)
                bar.progress(prog)
                status_text.text(f"ğŸ”¥ æƒæä¸­... {ticker} | ä¸‹è¼‰OK: {download_ok} | é‡èƒ½OK: {vol_ok} | å‘½ä¸­: {len(results)}")
                
                df = fetch_raw_data(ticker, period="1y") 
                if df is None: continue
                download_ok += 1
                
                if df['Volume'].iloc[-1] < (min_vol * 1000): continue
                vol_ok += 1

                df = add_technical_indicators(df)
                if df is None: continue

                match_result = check_stock_strategy_web(df, settings, ticker, chip_map)
                
                if debug_stock and debug_stock in ticker:
                     st.write(f"ğŸ” [è¨ºæ–·] {ticker} ç­–ç•¥æª¢æŸ¥çµæœ: {match_result}")

                if match_result:
                    code = ticker.split('.')[0]
                    # 5. é¿é›·é‡æª¢æŸ¥
                    if exclude_margin_surge:
                        m_change = margin_map.get(code, 0)
                        if m_change > 500:
                             if debug_stock and debug_stock in ticker: st.write(f"âŒ èè³‡çˆ†å¢ ({m_change}å¼µ) -> å‰”é™¤")
                             continue
                    
                    # 6. ç‡Ÿæ”¶æª¢æŸ¥ (é è¨­ -100 ä¸éæ¿¾)
                    rev_data = rev_map.get(code, {'yoy': 0, 'mom': 0})
                    if rev_data['yoy'] < min_revenue_yoy:
                        if debug_stock and debug_stock in ticker: st.write(f"âŒ ç‡Ÿæ”¶æˆé•·ä¸è¶³ ({rev_data['yoy']}%) -> å‰”é™¤")
                        continue

                    eps, pe, _ = get_stock_fundamentals_safe(ticker)
                    
                    if exclude_negative_pe:
                        if (eps is not None and eps < 0) or (pe is None):
                             if debug_stock and debug_stock in ticker: st.write(f"âŒ è™§æè‚¡ (EPS {eps}) -> å‰”é™¤")
                             continue
                    
                    is_match, chip_msg = match_result
                    curr = df.iloc[-1]
                    if strategy_mode == "èœ»èœ“é»æ°´ (ç¸®é‡å›æ¸¬)": bias = 0.0
                    elif pd.isna(curr['MA200']): bias = 0.0
                    else: bias = ((curr['Close'] - curr['MA200']) / curr['MA200']) * 100
                    
                    name = get_stock_name(code)
                    sector = get_stock_sector(code)
                    net_buy = int(chip_map.get(code, 0) / 1000) if chip_map else 0
                    
                    results.append({
                        "ä»£è™Ÿ": code, "åç¨±": name, "ç”¢æ¥­": sector,
                        "æ”¶ç›¤": round(curr['Close'], 2), 
                        "ä¹–é›¢(%)": round(bias, 2), "é‡(å¼µ)": int(curr['Volume']/1000),
                        "RSI": round(curr['RSI'], 2),
                        "æ³•äººè²·è¶…(å¼µ)": net_buy,
                        "ç‡Ÿæ”¶å¹´å¢(%)": rev_data['yoy'],
                        "ç‡Ÿæ”¶æœˆå¢(%)": rev_data['mom'],
                        "EPS": eps if eps else "N/A",
                        "æœ¬ç›Šæ¯”": pe if pe else "N/A",
                        "è³‡æ–™æ—¥æœŸ": df.index[-1].strftime('%Y-%m-%d'), "ç­–ç•¥": strategy_mode, "ç±Œç¢¼ç‹€æ…‹": chip_msg
                    })
                    
                    live_df = pd.DataFrame(results).sort_values(by="RSI", ascending=False)
                    # â˜… ä¿®æ­£ï¼šä½¿ç”¨ placeholder æ›´æ–°
                    live_result_placeholder.dataframe(
                        live_df,
                        column_config={
                            "RSI": st.column_config.ProgressColumn("RSI", format="%d", min_value=0, max_value=100),
                            "ç‡Ÿæ”¶å¹´å¢(%)": st.column_config.NumberColumn("ç‡Ÿæ”¶å¹´å¢", format="%.1f%%"),
                        },
                        hide_index=True
                    )
            
            bar.progress(1.0)
            status_text.text("âœ… æƒæå®Œæˆ")
            if results:
                st.success(f"æƒæå®Œæˆï¼ç™¼ç¾ {len(results)} å€‹ç›®æ¨™ï¼")
                save_to_history(results)
                
                if line_token:
                    msg = f"\nğŸ”¥ é»‘æ­¦å£«æˆ°å ± ({get_taiwan_time().strftime('%m/%d')})\n"
                    msg += f"ç­–ç•¥ï¼š{strategy_mode}\nç™¼ç¾ï¼š{len(results)} æª”\n"
                    for r in results[:3]:
                        msg += f"â€¢ {r['åç¨±']}({r['ä»£è™Ÿ']}): {r['æ”¶ç›¤']}å…ƒ / YoY {r['ç‡Ÿæ”¶å¹´å¢(%)']}%\n"
                    send_line_notify(line_token, msg)
                    st.toast("Line é€šçŸ¥å·²ç™¼é€")
            else: 
                st.warning("ä»Šæ—¥ç„¡ç›®æ¨™ã€‚å»ºè­°ä½¿ç”¨å´é‚Šæ¬„ã€è¨ºæ–·å·¥å…·ã€‘æª¢æŸ¥é€£ç·šã€‚")

    with tab2:
        st.header("ğŸ“œ æ­·å²ç´€éŒ„ (ç­–ç•¥åˆ†é¡ç‰ˆ)")
        df_hist = load_history()
        
        if df_hist is not None and not df_hist.empty:
            unique_dates = sorted(df_hist['ç¯©é¸æ—¥æœŸ'].unique(), reverse=True)
            for i, date_str in enumerate(unique_dates):
                is_expanded = (i == 0)
                with st.expander(f"ğŸ“… {date_str} æƒæç´€éŒ„", expanded=is_expanded):
                    df_day = df_hist[df_hist['ç¯©é¸æ—¥æœŸ'] == date_str].copy()
                    df_grouped = df_day.groupby(['ä»£è™Ÿ', 'åç¨±']).agg({
                        'ç­–ç•¥': lambda x: list(x),
                        'æ”¶ç›¤': 'last', 'RSI': 'last', 'ç”¢æ¥­': 'last', 
                        'æ³•äººè²·è¶…(å¼µ)': 'last', 'ç‡Ÿæ”¶å¹´å¢(%)': 'last'
                    }).reset_index()
                    df_grouped['ç­–ç•¥æ•¸'] = df_grouped['ç­–ç•¥'].apply(len)
                    
                    multi_hits = df_grouped[df_grouped['ç­–ç•¥æ•¸'] > 1].copy()
                    if not multi_hits.empty:
                        multi_hits['ç¬¦åˆç­–ç•¥'] = multi_hits['ç­–ç•¥'].apply(lambda x: ", ".join(x))
                        st.markdown("#### ğŸ”¥ å¤šé‡å…±æŒ¯ (åŒæ™‚ç¬¦åˆ2ç¨®ä»¥ä¸Š)")
                        st.dataframe(multi_hits.drop(columns=['ç­–ç•¥', 'ç­–ç•¥æ•¸']), hide_index=True,
                                     column_config={"RSI": st.column_config.ProgressColumn("RSI", min_value=0, max_value=100, format="%d")})
                    
                    st.markdown("#### âš”ï¸ å–®ä¸€ç­–ç•¥åˆ†é¡")
                    cols = st.columns(3)
                    for idx, strat in enumerate(VALID_STRATEGIES):
                        with cols[idx]:
                            st.write(f"**{strat}**")
                            df_s = df_day[df_day['ç­–ç•¥'] == strat].copy()
                            if not df_s.empty:
                                st.dataframe(
                                    df_s[['ä»£è™Ÿ', 'åç¨±', 'ç”¢æ¥­', 'æ”¶ç›¤', 'RSI', 'ç‡Ÿæ”¶å¹´å¢(%)']], 
                                    hide_index=True,
                                    column_config={"RSI": st.column_config.ProgressColumn("RSI", min_value=0, max_value=100, format="%d")}
                                )
                            else: st.caption("ç„¡è³‡æ–™")
        else: st.info("å°šç„¡ç´€éŒ„")

    with tab3:
        st.header("ğŸ“Š å€‹è‚¡åŸºæœ¬é¢å¥è¨º")
        c_fund, _ = st.columns([1,2])
        fund_ticker = c_fund.text_input("è¼¸å…¥ä»£è™Ÿ (ä¾‹å¦‚ 2330)", "")
        if c_fund.button("æŸ¥è©¢åŸºæœ¬é¢"):
             if fund_ticker:
                 eps, pe, roe = get_stock_fundamentals_safe(fund_ticker)
                 if eps is not None:
                     col_a, col_b, col_c = st.columns(3)
                     col_a.metric("æ¯è‚¡ç›ˆé¤˜ (EPS)", f"{eps} å…ƒ")
                     col_b.metric("æœ¬ç›Šæ¯” (PE)", f"{pe} å€")
                     col_c.metric("è‚¡æ±æ¬Šç›Šå ±é…¬ç‡ (ROE)", f"{round(roe*100, 2)}%" if roe else "N/A")
                     st.success(f"{fund_ticker} æ•¸æ“šç²å–æˆåŠŸ")
                 else: st.error("æŸ¥ç„¡æ•¸æ“š")

    with tab4:
        st.header("â³ é»‘æ­¦å£« - æ™‚å…‰å›æº¯")
        c1, c2 = st.columns([1, 2])
        target_stock = c1.text_input("è¼¸å…¥ä»£è™Ÿ (å›æ¸¬ç”¨)", "2330")
        if c1.button("é–‹å§‹å›æ¸¬"):
            clean_sid = target_stock.replace(".TW", "").replace(".TWO", "").strip()
            ticker = f"{clean_sid}.TW"
            with st.spinner(f"æ­£åœ¨å›æº¯ {ticker} éå» 5 å¹´èµ°å‹¢..."):
                df = fetch_stock_data(ticker, period="5y")
            if df is not None and len(df) > 100:
                signals = []
                results = []
                search_start = max(260, 60) if strategy_mode == "èœ»èœ“é»æ°´ (ç¸®é‡å›æ¸¬)" else max(260, df.index.get_loc(df['MA200'].first_valid_index()))
                for i in range(search_start, len(df)):
                    d_str = df.index[i].strftime('%Y-%m-%d')
                    is_sig, bias, loc = check_signal_on_date(df, d_str, settings, strict_mode=True)
                    if is_sig:
                        signals.append(d_str)
                        ret = calculate_forward_performance(df, loc)
                        price = df.iloc[loc]['Close']
                        results.append({
                            "è¨Šè™Ÿæ—¥æœŸ": d_str, "é€²å ´åƒ¹": round(price, 2),
                            "æ³¢æ®µæœ€é«˜æ¼²å¹…": f"{ret['æ³¢æ®µæœ€é«˜æ¼²å¹…(%)']}%",
                            "æœ€é«˜åƒ¹æ—¥æœŸ": ret['æœ€é«˜åƒ¹æ—¥æœŸ'], "æŒæœ‰å¤©æ•¸": ret['æŒæœ‰å¤©æ•¸']
                        })
                if results:
                    st.success(f"å›æ¸¬å®Œæˆï¼å…±å‡ºç¾ {len(results)} æ¬¡è²·é»ã€‚")
                    res_df = pd.DataFrame(results)
                    res_df['æ¼²å¹…æ•¸å€¼'] = res_df['æ³¢æ®µæœ€é«˜æ¼²å¹…'].str.replace('%','').astype(float)
                    res_df = res_df.sort_values('æ¼²å¹…æ•¸å€¼', ascending=False).drop(columns=['æ¼²å¹…æ•¸å€¼'])
                    st.dataframe(res_df)
                    selected_date = st.selectbox("é¸æ“‡æ—¥æœŸæŸ¥çœ‹ç•¶æ™‚ K ç·š", signals)
                    plot_candlestick(df, selected_date, clean_sid)
                else: st.warning("ç„¡ç¬¦åˆè¨Šè™Ÿã€‚")
            else: st.error("è³‡æ–™ä¸è¶³æˆ–ç„¡æ³•ä¸‹è¼‰ã€‚")

    with tab5:
        st.header("ğŸ“° å€‹è‚¡èˆ‡ç”¢æ¥­æƒ…å ±")
        col1, col2 = st.columns(2)
        with col1:
            st.subheader("ğŸ”¥ å€‹è‚¡/ç”¢æ¥­å‹•æ…‹")
            if st.button("æ›´æ–°æƒ…å ±"):
                news_list, keywords = get_all_market_news()
                if news_list:
                    if keywords:
                        kw_count = Counter(keywords).most_common(5)
                        kw_text = " ".join([f"#{k[0]}" for k in kw_count])
                        st.info(f"ç†±é»: {kw_text}")
                    for n in news_list:
                        st.markdown(f"""
                        <div style="padding: 10px; border-bottom: 1px solid #ddd;">
                            <span style="color:gray; font-size:12px;">[{n['ä¾†æº']}]</span><br>
                            <a href="{n['é€£çµ']}" target="_blank" style="font-size: 16px; font-weight:bold;">{n['æ¨™é¡Œ']}</a>
                        </div>
                        """, unsafe_allow_html=True)
                else: st.warning("æš«ç„¡ç›¸é—œæ–°è")
        with col2:
            st.subheader("ğŸ’° è³‡é‡‘æµå‘ (å‹•æ…‹è®ŠåŒ–)")
            if st.button("æ›´æ–°è³‡é‡‘æµå‘"):
                main_s, flow_in, flow_out, d_date = get_twse_sector_flow_dynamic()
                if main_s is not None:
                    st.success(f"è³‡æ–™æ—¥æœŸ: {d_date} (æ¯”è¼ƒæ˜¨æ—¥è®ŠåŒ–)")
                    st.write("ğŸ“ˆ **è³‡é‡‘æ¹§å…¥ (è®Šå‹•ç‡ +%)**")
                    st.dataframe(flow_in, hide_index=True)
                    st.write("ğŸ“‰ **è³‡é‡‘æ’¤é€€ (è®Šå‹•ç‡ -%)**")
                    st.dataframe(flow_out, hide_index=True)
                    st.write("ğŸ“Š **ä¸»æµæ¿å¡Š (æˆäº¤é‡‘é¡æœ€å¤§)**")
                    st.dataframe(main_s, hide_index=True)
                else: st.error(f"ç„¡æ³•å–å¾—è³‡æ–™: {d_date}")
        st.markdown("---")
        st.subheader("ğŸ† æ³•äººæƒè²¨æ¦œ (æ™ºæ…§æ¨™ç±¤)")
        if st.button("æŸ¥çœ‹æ³•äººè²·è¶…"):
            rank_df, date_str = get_institutional_ranking_smart()
            if rank_df is not None:
                st.success(f"è³‡æ–™æ—¥æœŸ: {date_str}")
                st.dataframe(rank_df, hide_index=True)
            else: st.error(f"ç„¡æ³•å–å¾—è³‡æ–™: {date_str}")

    with tab6:
        st.header("ğŸš€ æ½›åŠ›é£†è‚¡é›·é”")
        if st.button("å•Ÿå‹•é›·é”åµæ¸¬"):
            with st.spinner("äº¤å‰æ¯”å°ä¸­..."):
                _, flow_in, _, _ = get_twse_sector_flow_dynamic()
                rank_df, _ = get_institutional_ranking_smart()
                news_list, _ = get_all_market_news()
                if flow_in is not None and rank_df is not None:
                    st.success("âœ… åˆ†æå®Œæˆ")
                    hot_sectors = flow_in['åˆ†é¡æŒ‡æ•¸åç¨±'].tolist()
                    st.write(f"ğŸ”¥ å¼·å‹¢æ¿å¡Šï¼š{', '.join(hot_sectors)}")
                    matches = []
                    for index, row in rank_df.iterrows():
                        stock_name = row['åç¨±']
                        stock_status = row['ç‹€æ…‹']
                        related_news = []
                        for n in news_list:
                            if stock_name in n['æ¨™é¡Œ']: related_news.append(n['æ¨™é¡Œ'])
                        if "çˆ†è²·" in stock_status or ("é€£è²·" in stock_status and len(related_news) > 0):
                            matches.append({
                                "ä»£è™Ÿ": row['ä»£è™Ÿ'], "åç¨±": stock_name,
                                "ç‹€æ…‹": stock_status,
                                "æ–°èä½è­‰": related_news[0] if related_news else "ç„¡",
                                "å¼·åº¦": "â­â­â­" if "çˆ†è²·" in stock_status else "â­â­"
                            })
                    if matches: st.dataframe(pd.DataFrame(matches))
                    else: st.warning("ç„¡æ˜é¡¯å…±æŒ¯è¨Šè™Ÿ")
                else: st.error("æ•¸æ“šä¸è¶³")

    with tab7:
        st.header("ğŸŒ¡ï¸ å…¨å°è‚¡å¸‚è³‡é‡‘ç†±åŠ›åœ– (Maxç‰ˆ)")
        st.info("æ–¹å¡Šå¤§å° = æˆäº¤é‡‘é¡ | é¡è‰² = æ¼²è·Œå¹… | é«˜åº¦å·²èª¿æ•´ç‚º 1200px")
        if st.button("ç”Ÿæˆç†±åŠ›åœ–"):
            with st.spinner("æ­£åœ¨æŠ“å–å…¨å¸‚å ´æ•¸æ“š..."):
                df_heat, date_str = get_tw_market_heatmap_data()
            if df_heat is not None:
                st.success(f"è³‡æ–™æ—¥æœŸ: {date_str} (å‰400å¤§æˆäº¤è‚¡)")
                fig = px.treemap(
                    df_heat,
                    path=['ç”¢æ¥­', 'æ¨™ç±¤'],
                    values='æˆäº¤é‡‘é¡',
                    color='æ¼²è·Œå¹…%',
                    color_continuous_scale=['#00da3c', '#ffffff', '#ff0000'],
                    color_continuous_midpoint=0,
                    range_color=[-10, 10],
                    title=f"å°è‚¡è³‡é‡‘ç†±åŠ›åœ– (ç´°åˆ†æ—ç¾¤ç‰ˆ) - {date_str}"
                )
                fig.update_layout(width=1200, height=900, margin=dict(t=50, l=10, r=10, b=10))
                fig.update_traces(textinfo="label+value", textfont_size=20)
                st.plotly_chart(fig, use_container_width=True)
            else: st.error("ç„¡æ³•å–å¾—ç†±åŠ›åœ–æ•¸æ“š")

    with tab8:
        st.header("ğŸ§ª ç­–ç•¥å¯¦é©—å®¤ (æ¨¡æ“¬æŒæœ‰è‡³ä»Š)")
        st.info("ç³»çµ±å°‡è®€å–æ­·å²ç´€éŒ„ï¼Œæ¨¡æ“¬ã€Œè‹¥ç•¶åˆè²·é€²æŒæœ‰åˆ°ä»Šå¤©ã€çš„ç¸¾æ•ˆã€‚")
        
        if st.button("é–‹å§‹æ¨¡æ“¬æ¼”ç·´"):
            df_hist = load_history()
            
            if df_hist is None or df_hist.empty:
                st.warning("âš ï¸ ç„¡æ­·å²ç´€éŒ„ï¼Œè«‹å…ˆæƒæã€‚")
            else:
                results = []
                all_data = df_hist.drop_duplicates(subset=['ä»£è™Ÿ', 'ç¯©é¸æ—¥æœŸ', 'ç­–ç•¥'])
                total_len = len(all_data)
                bar = st.progress(0.0)
                
                for i, row in all_data.iterrows():
                    bar.progress(min(1.0, (i + 1) / total_len))
                    ticker = f"{row['ä»£è™Ÿ']}.TW"
                    entry_date = row['ç¯©é¸æ—¥æœŸ']
                    entry_price = row.get('é€²å ´åƒ¹', row.get('æ”¶ç›¤')) 
                    
                    if pd.isna(entry_price): continue
                    
                    try:
                        df_sim = yf.Ticker(ticker).history(period="1y")
                        if df_sim.empty: continue
                        df_sim.index = df_sim.index.tz_localize(None)
                        entry_dt = pd.to_datetime(entry_date)
                        df_hold = df_sim[df_sim.index >= entry_dt]
                        
                        if len(df_hold) < 1: continue 
                        curr_price = df_hold.iloc[-1]['Close']
                        final_pl = ((curr_price - entry_price) / entry_price) * 100
                        
                        results.append({
                            "ç­–ç•¥": row['ç­–ç•¥'],
                            "ä»£è™Ÿ": row['ä»£è™Ÿ'], "åç¨±": row['åç¨±'],
                            "é€²å ´æ—¥æœŸ": entry_date, "é€²å ´åƒ¹": round(entry_price, 2),
                            "ç¾åƒ¹": round(curr_price, 2), "å ±é…¬ç‡(%)": round(final_pl, 2)
                        })
                    except: continue
                
                bar.progress(1.0)
                
                if results:
                    st.success(f"æ¼”ç·´å®Œæˆï¼å…± {len(results)} ç­†ã€‚")
                    df_res = pd.DataFrame(results)
                    available_strats = df_res['ç­–ç•¥'].unique()
                    strat_tabs = st.tabs([f"âš”ï¸ {s}" for s in available_strats])
                    
                    for idx, strat in enumerate(available_strats):
                        with strat_tabs[idx]:
                            df_s = df_res[df_res['ç­–ç•¥'] == strat]
                            avg_ret = df_s['å ±é…¬ç‡(%)'].mean()
                            win_rate = (df_s['å ±é…¬ç‡(%)'] > 0).sum() / len(df_s) * 100
                            max_win = df_s['å ±é…¬ç‡(%)'].max()
                            
                            c1, c2, c3, c4 = st.columns(4)
                            c1.metric("äº¤æ˜“æ¬¡æ•¸", len(df_s))
                            c2.metric("å¹³å‡å ±é…¬", f"{avg_ret:.2f}%")
                            c3.metric("å‹ç‡", f"{win_rate:.1f}%")
                            c4.metric("æœ€é«˜ç²åˆ©", f"{max_win:.2f}%")
                            st.markdown("---")
                            
                            unique_dates = sorted(df_s['é€²å ´æ—¥æœŸ'].unique(), reverse=True)
                            for d in unique_dates:
                                df_day = df_s[df_s['é€²å ´æ—¥æœŸ'] == d].copy()
                                day_avg = df_day['å ±é…¬ç‡(%)'].mean()
                                day_color = "ğŸŸ¢" if day_avg > 0 else "ğŸ”´"
                                with st.expander(f"{day_color} {d} (å‡å ±é…¬ {day_avg:.1f}%)"):
                                    st.dataframe(
                                        df_day[['ä»£è™Ÿ', 'åç¨±', 'é€²å ´åƒ¹', 'ç¾åƒ¹', 'å ±é…¬ç‡(%)']],
                                        hide_index=True, use_container_width=True,
                                        column_config={
                                            "å ±é…¬ç‡(%)": st.column_config.ProgressColumn(
                                                "æç›Š", format="%.2f%%", min_value=-20, max_value=20
                                            )
                                        }
                                    )
                else: st.warning("ç„¡æ¨¡æ“¬çµæœ")

except Exception as e:
    st.error(f"ç™¼ç”ŸéŒ¯èª¤: {e}")
